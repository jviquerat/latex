%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{A bit of History}

The first observations of electric and magnetic phenomena by man date back to 600 B.C., when Thales of Miletus observed the property of amber to attract light objects, such as fabric, after being rubbed with fur. In the same period, he also reported the existing attraction between lodestone and iron. Three centuries later, Euclid threw together the basis of geometrical optics in \textit{Optica}, describing the laws of reflection and postulating that light travels in straight lines. From this point, the studies of electromagnetism and light followed parallel paths, until the XIX${}^{\text{th}}$ century. In 1848 and 1850, Hippolyte Fizeau and L\'eon Foucault measured the speed of light respectively at \num{3.14e8} and \num{2.98e8} m.s${}^{-1}$. In 1855, Wilhelm Eduard Weber and Rudolf Kohlrausch found out through an experimentation that the ratio of the electromagnetic to the electrostatic unit charge was close to \num{3.107e8} m.s${}^{-1}$. Although the values from Fizeau and Foucault were known at that time, they did not notice the alikeness of the results \cite{Keithley1}.

It is only in 1861 that James Clerk Maxwell, looking at Weber and Kohlrausch's results, established the existing link between light propagation and electromagnetic phenomena. In \cite{Maxwell1}, he concludes : "\emph{The agreement of the results seems to show that light and magnetism are affections of the same substance, and that light is an electromagnetic disturbance propagated through the field according to electromagnetic laws}". At that stage, Maxwell's theory of electromagnetism is regrouped in a set of twenty unknowns and equations, that will then be converted into modern notations by a concurrent work of Olivier Heaviside, Josiah Willard Gibbs and Heinrich Hertz in 1884. It should be noted that the 1861 formulation of Maxwell still relies on the existence of the \emph{luminiferous aether}, a postulated medium necessary to the propagation of light. For more than forty years, the latter will be a source of conflict, his properties being very difficult to accept in the physical paradigm of that time. In 1905, Einstein's special theory of relativity finally provided a framework that did not require the presence of aether anymore.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Nano-optics}

Maxwell's equations in their modern form have been studied for many decades, resulting in an extremely wide range of applications. Many of those are now part of our everyday life, such as wireless communications of all forms, optical fibers, medical imaging, ... In order to control electromagnetic wave propagation, most of these devices rely on tailored geometries and materials. During the last decades, the evolution of lithography techniques allowed the creation of geometrical structures at the nanometer scale, thus unveiling a variety of new phenomena arising from light-matter interactions at such levels. These effects usually occur when the device is of comparable size or (much) smaller than the wavelength of the incident field. Periodic mono- or multi-dimensional arrangements of sub-wavelength dielectric patterns, known as \emph{photonic crystals} (see figure \ref{fig:cristaux}), give rise to allowed and forbidden wavelengths regions in certain directions \cite{Johnson1}. These so-called \emph{band gaps} can be tuned by slight modifications of the periodicity, allowing physicists to create a full range of light-control devices from photonic crystals. Periodic arrays of dielectric resonators can also be used to achieve non-cartesian reflection of plane waves, which is a highly promising step toward on-chip wireless optical communications \cite{Zou1}.

\input{fig/intro/cristaux} 

Metallic nanostructures can also demonstrate stunning effects when excited in the optical regime. The key feature of these effects is the coupling of the electromagnetic field to the electron gas of the metal, resulting in an oscillation phenomenon called \emph{plasmon}. One usually differentiates the \emph{bulk} plasmons, that take place in the volume, from the \emph{surface} plasmons (SP), that arise at the interface between the metal and a dielectric. SPs can be propagative along a metal/dielectric interface, or non-propagative, in which case they are called \emph{localized} surface plasmons (LSPs). The proper excitation of LSPs can lead to very intense resonances (meaning that the field is enhanced). Thanks to metallic tips exploiting this strong localization, optical microscopy beyond the diffraction limit \cite{Novotny1} is possible. The high sensitivity of resonant metallic nanostructures also allows to create very accurate biosensors \cite{Chung1}. In the medical field, attempts have been made to develop cancer therapies based on the localized heating produced with resonating nano particles \cite{Sotiriou1}. As for dielectrics, periodic arrays of metallic patterns can lead to new devices with non-natural behaviors at larger scales. These structures are usually gathered under the root word \emph{metamaterials}, which then designates an effective medium composed of an arrangement of nanostructures, and displaying uncommon properties. Negative refractive index materials \cite{Dolling1} or optical cloaking \cite{Cai1} are some of the most common examples.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Computational electromagnetics in time-domain}

The large variety of phenomena displayed by nano-optic systems, their dependance upon a large number of parameters (geometry, materials, sources, ...), as well as the complexity of most fabrication processes prevent physicists from relying on experiments only. However, apart from very specific cases involving simple geometries, and for which electromagnetic fields can be expressed as closed-forms, solutions to Maxwell's equations are out of reach of hand calculations. Hence, numerical simulation seems to be the appropriate complementary tool to physical experiments, and can be exploited in various ways. Indeed, it can be used to rapidly scan a large number of configurations, in order to identify the most efficient set of parameters. This scanning can be done "blindly" by hand if a small number of parameters is involved, or by combining a direct numerical method to an iterative optimization algorithm when the dimension of the parameters space becomes large \cite{Pavaskar1}. Numerical tools also allow a deeper understanding of the physical phenomena observed in real devices, since they allow the experimentalist to obtain information about any quantity out of the simulation, which is not possible in most physical experiments. Additionally, various physical models can be easily assessed and their effects compared, in order to verify their applicability in given configurations. Various techniques are available to solve nano-optics problems: some are specialized algorithms, that were developed for the fast-solving of specific configurations at low computational cost (for example the Discrete Dipole Approximation (DDA) \cite{Draine1} or the Rigorous Coupled-Wave Analysis (RCWA) \cite{Moharam1}). However, these can hardly or not at all handle other applications. On the other hand, more general methods exist that are well suited to solve a very large set of problems. In the remaining of this section, we focus on the major time-domain techniques.

The Finite-Difference Time-Domain (FDTD) method is certainly the most spread of all. As early as 1928, Courant, Friedrichs and Lewy published an article presenting a finite-difference scheme for the second order wave equation in 1D and 2D, as well as the well-known CFL stability condition involved for explicit time-domain schemes \cite{Courant1}. In 1966, Yee introduced a staggered grid in space (see figure \ref{fig:yee_cell}) to solve the curl formulation of Maxwell's equations \cite{Yee1}. The method relies on a combination of Taylor expansions to express the spatial derivatives, and on a centered Leap-Frog (LF) scheme in time. As of today, FD represent a particularly simple method to solve electromagnetics problems, combining simple implementation and high computational efficiency. They were applied successfully to numerous nano-optics configurations \cite{Salski1}.

\input{fig/intro/yee_cell}

However, FD algorithms suffer from serious drawbacks. First, a smooth discretization of curved geometries is impossible due to the fixed cartesian grid imposed by the Yee algorithm. This approximation leads to the well-known \emph{staircasing effect}, which is an important source of inaccuracy \cite{Ditkowski1}. To overcome this pitfall, the user can either use an extreme refinement of the grid, which leads to a serious rise in computational cost, or exploit one of the numerous possible modifications of the FD method that have been proposed for tackling the staircasing effect \cite{Hao1}. However, all the latter available modifications represent a tradeoff between the simplicity of the classical algorithm and the accuracy of the boundary description. The second main source of inaccuracy in the FDTD method arises in the case of heterogeneous problems. In this case, the Taylor approximation used is no longer valid, since the electromagnetic fields are not smooth across the interface. The consequence is that higher-order FD schemes in space are usually reduced to second-order. Advanced FDTD methods were developed to tackle this problem \cite{Taflove1}, at the price of an increased complexity of the algorithm. Moreover, there is no theoretical convergence proof for FDTD algorithms outside the uniform grid case.

Finite Elements (FE) were introduced in 1969 by Silvester to solve waveguide problems \cite{Silvester1}. This method does not rely on a grid, but on a tessellation of the geometry of the problem. Starting from the continuous equations, a discrete variational form is obtained by approximating the unknowns in a finite dimensional space. Then, its discretization leads to a sparse matrix-vector system that has to be solved at each timestep. In the specific case of electromagnetism, the use of \emph{nodal} basis functions, \eg such as their value is unity at a given vertex and zero on every other, is subject to caution. Indeed, it was proved that they can lead to spurious oscillations, due to an ill representation of the curl kernel \cite{Sun1}. To overcome this issue, N\'ed\'elec introduced a new family of vector finite elements in 1986 \cite{Nedelec1}, named \emph{N\'ed\'elec finite elements}, or \emph{edge finite elements}. These elements display several interesting properties: (i) their divergence is zero, and (ii) each basis function associated to an edge has a constant tangential component on the latter, and a zero tangential component on the others. Hence, the tangential continuity of the electric field across the edge is naturally enforced.

In order to adjust the accuracy of the simulation, FE methods can use either (i) a local refinement or coarsening of the mesh, (ii) a local or global increase of the order of the basis functions, or (iii) a combination of both. However, these improvements lead to larger linear systems to solve at each timestep, which can make the FE method impractical in time-domain simulations for very large systems. For this reason, in nano-optics, FE methods are more often used in frequency-domain. However, a few references can be found exploiting time-domain FE for nanophotonics applications \cite{Huang1}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The Discontinuous Galerkin Time-Domain method}

Discontinuous Galerkin (DG) methods were originally introduced in 1973 by Reed and Hill \cite{Reed1}, and have been widely used since in the computational fluid dynamics field. However, their application to the time-domain Maxwell equations is more recent \cite{Remaki1}. DG methods can be seen as classical finite element methods for which the global continuity of the approximation is lifted. In the same fashion as FE methods, the unknowns are approximated on a finite set of basis functions. However, for DG, the support of basis functions are restrained to a single discretization cell. Hence, the solution produced by a DG method is discontinuous (similarly to finite volumes), and multiple different field values are stored for each element/element interface degree of freedom (see figure \ref{fig:methods}). The three main consequences are that (i) DG methods naturally handle material and field discontinuities, (ii) the weak formulation is local to an element, implying no large mass matrix inversion in the solving process, and (iii) the order of polynomial approximation in space can be made arbitrarily high by adding more degrees of freedom inside the elements. However, this also means that DG methods have higher memory requirements than standard FE methods. Afterward, connexion between the cells is restored by the use of a numerical flux, in the fashion of finite volume methods. The choice of the numerical flux has a great influence on the mathematical properties of the DG discretization, as energy preservation, for example. 

\input{fig/intro/methods}

The discontinuity of the approximation makes room for numerous methodological improvements, such as efficient parallelization (\cite{Diehl1}, \cite{Bernacki1}) or the use of non-conforming \cite{Fahs2} and hybrid meshes \cite{Leger1}. Recent studies in the DG framework include local timestepping \cite{Piperno1} as well as locally implicit formulations \cite{Moya1}. Also, a wide choice of time-integration schemes can be used for the discretization of time derivatives, including Leap-Frog (LF) and Runge-Kutta (RK).

The DGTD method for solving the time domain Maxwell equations is increasingly adopted by several physics communities. Concerning nanophotonics, unstructured mesh based DGTD methods have been developed and have demonstrated their potentialities for being considered as viable alternatives to the FDTD method. The most remarkable achievements in the  nanophotonics domain since 2009 are due to Busch {\em et al}. Busch \cite{Niegemann4}-\cite{Stannigel1}-\cite{Busch1} has been at the origin of seminal works on the development and application of the DGTD method in this domain. These works not only deal with the extension of the DGTD method with regards to the complex material models and source  settings required by applications relevant to nanophotonics and plasmonics \cite{Konig1}-\cite{Matyssek1}-\cite{Wolff1}, but also to core contributions aiming at improving the accuracy and the efficiency of the proposed DGTD solvers \cite{Niegemann2}-\cite{Niegemann3}-\cite{Demirel1}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Outline}

The remaining of this manuscript is structured in the following way:

\begin{enumerate}
	\item Chapter 2 presents the usual concepts of electromagnetics, as well as some standard textbook problems and their analytical solutions. An extensive presentation and analysis of dispersive models for metals follows, along with a comparison of our custom generalized dispersive model with other classical dispersion models.
	\item The first section of chapter 3 runs, step by step, through the spatial discretization of Maxwell's equations by the discontinuous Galerkin method. Then, two classical time integration methods are proposed and briefly studied to complete the discretization. The algorithm is then validated for classical and dispersive materials. Finally, a few theoretical results are given on the method.
	\item Chapter 4 regroups practical techniques that are pre-requisites for the resolution of realistic problems, such as perfectly-matched layers, sources, total-field scattered-field technique, as well as physical post-treatments.
	\item In chapter 5, the DG method is extended to the use of quadratic tetrahedra, which allow both a better geometrical description of the problems, and lifts the numerical accuracy limit from $2^{nd}$ to $4^{th}$ order in the case of curved geometries. Several nano-optics relevant test-cases are considered that confort the interest of this development.
	\item Chapter 6 is dedicated to a locally-adaptive DG formulation, where polynomial interpolation order can be defined independently in each cell of the mesh. An efficient repartition algorithm is supplied, which provides interesting speedups over homogeneous polynomial repartition in several realistic test-cases.
	\item The sequential and parallel performances of our Fortran discontinuous Galerkin time-domain (DGTD) implementation are assessed in chapter 7. First, a renumbering algorithm is proposed that enhances the sequential performances by reducing adressing time. Then, the speedup and parallel balance of the MPI implementation are tested on a standard cavity case.
	\item The last chapter is dedicated to realistic nanophotonics computations processed with our DGTD code: (i) the electron energy loss spectrum (EELS) of an aluminium nanosphere, (ii) the gap-plasmon resonances obtained under chemically-produced nanocubes with realistic shapes, and (iii) 1D and 2D dielectric reflectarrays, with study of the lithography defects on their performances.
\end{enumerate}
